{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Python 2 vs 3\n",
    "## Conda\n",
    "## Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing VCF - adding readcounts using bam-readcount and VAtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this module we'll be working with a somatic exome VCF file created by the Mutect variant caller with some basic filtering already done. This VCF can be found in the `week_09` folder of the [bfx-workshop repository](https://github.com/genome/bfx-workshop). Let's create a working directory and download this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ssiebert/Documents/Work/bfx-workshop/week_09\n",
      "--2020-11-13 09:43:38--  https://github.com/genome/bfx-workshop/blob/master/week_09/mutect.filtered.vcf.gz?raw=true\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/genome/bfx-workshop/raw/master/week_09/mutect.filtered.vcf.gz [following]\n",
      "--2020-11-13 09:43:38--  https://github.com/genome/bfx-workshop/raw/master/week_09/mutect.filtered.vcf.gz\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/genome/bfx-workshop/master/week_09/mutect.filtered.vcf.gz [following]\n",
      "--2020-11-13 09:43:38--  https://raw.githubusercontent.com/genome/bfx-workshop/master/week_09/mutect.filtered.vcf.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.184.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.184.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 96958 (95K) [application/octet-stream]\n",
      "Saving to: ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/mutect.filtered.vcf.gz’\n",
      "\n",
      "/Users/ssiebert/Doc 100%[===================>]  94.69K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2020-11-13 09:43:39 (3.91 MB/s) - ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/mutect.filtered.vcf.gz’ saved [96958/96958]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!echo $PWD\n",
    "!mkdir -p $PWD/bfx_workshop_week_09\n",
    "!wget https://github.com/genome/bfx-workshop/blob/master/week_09/mutect.filtered.vcf.gz?raw=true -O $PWD/bfx_workshop_week_09/mutect.filtered.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the reference and tumor bam files used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-13 09:43:39--  https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa?_ga=2.128927176.-570225801.1605281431\n",
      "Resolving storage.cloud.google.com (storage.cloud.google.com)... 172.217.1.46\n",
      "Connecting to storage.cloud.google.com (storage.cloud.google.com)|172.217.1.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://accounts.google.com/ServiceLogin?service=cds&passive=1209600&continue=https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa?_ga%3D2.128927176.-570225801.1605281431&followup=https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa?_ga%3D2.128927176.-570225801.1605281431 [following]\n",
      "--2020-11-13 09:43:39--  https://accounts.google.com/ServiceLogin?service=cds&passive=1209600&continue=https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa?_ga%3D2.128927176.-570225801.1605281431&followup=https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa?_ga%3D2.128927176.-570225801.1605281431\n",
      "Resolving accounts.google.com (accounts.google.com)... 216.58.192.141\n",
      "Connecting to accounts.google.com (accounts.google.com)|216.58.192.141|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/hla_and_brca_genes.fa’\n",
      "\n",
      "/Users/ssiebert/Doc     [ <=>                ]  61.05K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2020-11-13 09:43:39 (1.61 MB/s) - ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/hla_and_brca_genes.fa’ saved [62514]\n",
      "\n",
      "--2020-11-13 09:43:39--  https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa.fai?_ga=2.60688873.-570225801.1605281431\n",
      "Resolving storage.cloud.google.com (storage.cloud.google.com)... 172.217.1.46\n",
      "Connecting to storage.cloud.google.com (storage.cloud.google.com)|172.217.1.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://accounts.google.com/ServiceLogin?service=cds&passive=1209600&continue=https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa.fai?_ga%3D2.60688873.-570225801.1605281431&followup=https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa.fai?_ga%3D2.60688873.-570225801.1605281431 [following]\n",
      "--2020-11-13 09:43:39--  https://accounts.google.com/ServiceLogin?service=cds&passive=1209600&continue=https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa.fai?_ga%3D2.60688873.-570225801.1605281431&followup=https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa.fai?_ga%3D2.60688873.-570225801.1605281431\n",
      "Resolving accounts.google.com (accounts.google.com)... 216.58.192.141\n",
      "Connecting to accounts.google.com (accounts.google.com)|216.58.192.141|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/hla_and_brca_genes.fa.fai’\n",
      "\n",
      "/Users/ssiebert/Doc     [ <=>                ]  60.89K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2020-11-13 09:43:40 (1.78 MB/s) - ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/hla_and_brca_genes.fa.fai’ saved [62348]\n",
      "\n",
      "--2020-11-13 09:43:40--  https://xfer.genome.wustl.edu/gxfer1/project/cancer-genomics/bfx_workshop/tumor.bam\n",
      "Resolving xfer.genome.wustl.edu (xfer.genome.wustl.edu)... 128.252.233.42\n",
      "Connecting to xfer.genome.wustl.edu (xfer.genome.wustl.edu)|128.252.233.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 128053546 (122M)\n",
      "Saving to: ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/tumor.bam’\n",
      "\n",
      "/Users/ssiebert/Doc 100%[===================>] 122.12M  13.6MB/s    in 9.0s    \n",
      "\n",
      "2020-11-13 09:43:49 (13.5 MB/s) - ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/tumor.bam’ saved [128053546/128053546]\n",
      "\n",
      "--2020-11-13 09:43:49--  https://xfer.genome.wustl.edu/gxfer1/project/cancer-genomics/bfx_workshop/tumor.bam.bai\n",
      "Resolving xfer.genome.wustl.edu (xfer.genome.wustl.edu)... 128.252.233.42\n",
      "Connecting to xfer.genome.wustl.edu (xfer.genome.wustl.edu)|128.252.233.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2208712 (2.1M)\n",
      "Saving to: ‘/Users/ssiebert/Documents/Work/bfx-workshop/week_09/bfx_workshop_week_09/tumor.bam.bai’\n",
      "\n",
      "week_09/bfx_worksho  54%[=========>          ]   1.15M  14.8KB/s    eta 1m 44s "
     ]
    }
   ],
   "source": [
    "!wget https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa?_ga=2.128927176.-570225801.1605281431 -O $PWD/bfx_workshop_week_09/hla_and_brca_genes.fa\n",
    "!wget https://storage.cloud.google.com/analysis-workflows-example-data/somatic_inputs/hla_and_brca_genes.fa.fai?_ga=2.60688873.-570225801.1605281431 -O $PWD/bfx_workshop_week_09/hla_and_brca_genes.fa.fai\n",
    "!wget https://xfer.genome.wustl.edu/gxfer1/project/cancer-genomics/bfx_workshop/tumor.bam -O $PWD/bfx_workshop_week_09/tumor.bam\n",
    "!wget https://xfer.genome.wustl.edu/gxfer1/project/cancer-genomics/bfx_workshop/tumor.bam.bai -O $PWD/bfx_workshop_week_09/tumor.bam.bai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting multialleleic sites using vt decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our VCF might contain variants with multiple alt alleles. In these cases the ALT field of the VCF will have multiple alt alleles in it. Take for example this variant:\n",
    "```\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tExome_Normal\tExome_Tumor\n",
    "chr17\t3017916\t.\tCGTGT\tC,CGT\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30,30;MFRL=0,0,0;MMQ=60,60,60;MPOS=49,31;NALOD=0.710,-7.297e+00;NLOD=2.65,-6.178e+00;POPAF=6.00,6.00;RPA=16,14,15;RU=GT;STR;STRQ=93;TLOD=6.76,12.45\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,0,3:0.066,0.271:12:0,0,0:8,0,3:9,0,3,0\t0/1/2:22,3,6:0.117,0.205:31:0,0,0:22,3,6:22,0,9,0\n",
    "```\n",
    "This might happen if both chromsomes have a mutation at the same position, but the exact mutation differs between the two chromosomes. It might also happen if there is a subclonal mutation in some tumor cells. It might also just be an artifact.\n",
    "\n",
    "It is usually easier to process a VCF if these sort of variants are preprocessed to split up multi-allelic sites since some information is encoded on a per-allele basis (e.g., per-allele depth, per-allele VAF). \n",
    "\n",
    "vt decompose is part of the [vt tool package](https://genome.sph.umich.edu/wiki/Vt) and available on quay container at `quay.io/biocontainers/vt:0.57721--hf74b74d_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_09:/data -it quay.io/biocontainers/vt:0.57721--hf74b74d_1 vt decompose /data/mutect.filtered.vcf.gz -s -o /data/mutect.filtered.decomposed.vcf.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running vt decompose the above variant is split up into two lines and looks like this:\n",
    "```\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tExome_Normal\tExome_Tumor\n",
    "chr17\t3017916\t.\tCGTGT\tC\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30;MFRL=0,0;MMQ=60,60;MPOS=49;NALOD=0.71;NLOD=2.65;POPAF=6;RPA=16,14;RU=GT;STR;STRQ=93;TLOD=6.76;OLD_MULTIALLELIC=chr17:3017916:CGTGT/C/CGT\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,0:0.066:12:0,0:8,0:9,0,3,0\t0/1/.:22,3:0.117:31:0,0:22,3:22,0,9,0\n",
    "chr17\t3017916\t.\tCGTGT\tCGT\t.\tgermline;multiallelic;normal_artifact\tAS_FilterStatus=weak_evidence|SITE;AS_SB_TABLE=31,0|3,0|9,0;DP=48;ECNT=1;GERMQ=1;MBQ=30,30;MFRL=0,0;MMQ=60,60;MPOS=31;NALOD=-7.297;NLOD=-6.178;POPAF=6;RPA=16,15;RU=GT;STR;STRQ=93;TLOD=12.45;OLD_MULTIALLELIC=chr17:3017916:CGTGT/C/CGT\tGT:AD:AF:DP:F1R2:F2R1:SB\t0/0:9,3:0.271:12:0,0:8,3:9,0,3,0\t0/./1:22,6:0.205:31:0,0:22,6:22,0,9,0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bam-readcount\n",
    "Some variant callers will already output read depth and allelic depths but this is useful in cases where this information is not already present in the VCF. This is also useful if you run RNAseq on top of somatic variant calling to add RNA coverage information to your VCF.\n",
    "\n",
    "We will be using the `mgibio/bam_readcount_helper-cwl:1.1.1` docker container to run bam-readcount. This Docker image already has bam-readcount installed and it also contains a script that will take care of creating a region list from your VCF, which is a required input to bam-readcount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required inputs\n",
    "- vcf\n",
    "- sample name\n",
    "- reference fasta\n",
    "- bam file\n",
    "- output file prefix\n",
    "- output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD/bfx_workshop_week_09:/data -it mgibio/bam_readcount_helper-cwl:1.1.1 python /usr/bin/bam_readcount_helper.py /data/mutect.filtered.decomposed.vcf.gz Exome_Tumor /data/hla_and_brca_genes.fa /data/tumor.bam Exome_Tumor /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAtools\n",
    "[VAtools](http://www.vatools.org) is a python package that provides a suite of tools that help with processing VCF annotations. We will be using the [vcf-readcount-annotator tool](https://vatools.readthedocs.io/en/latest/vcf_readcount_annotator.html) included with VAtools to write the readcounts calculated in the previous step to our VCF. VAtools is available as a Docker image at `griffithlab/vatools:4.1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -v $PWD:/data -it griffithlab/vatools:4.1.0 vcf-readcount-annotator /data/mutect.filtered.decomposed.vcf.gz bam_readcount_file DNA -s Exome_Tumor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing VCFs in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyVCF vs VCFPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyVCF](https://pyvcf.readthedocs.io/en/latest/) is the \"original\" Python VCF parser. It does a good job reading VCFs but doesn't support modifying VCF entries very well. It also doesn't appear to be maintained anymore. [VCFPy](https://vcfpy.readthedocs.io/en/stable/) was created to solve this problem. For that reason we'll be using VCFPy for the next tasks.\n",
    "\n",
    "First, we need to ensure that the `vcfpy` package is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install vcfpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in a VCF and exploring its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the VCF reader object from your VCF path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader = vcfpy.Reader.from_path(\"input.vcf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which samples are in your VCF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.samples.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which FILTERS are defined in the VCF header?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.filters_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar methods `info_ids` and `format_ids` exist for the INFO and FORMAT fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information for a specific INFO header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.header.get_info_field_info('sth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information for each variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in vcf_reader:\n",
    "    #Get the value of a specific FILTER \n",
    "    entry.FILTER['sth']\n",
    "    #Get the VAFs of a variant\n",
    "    calls = entry.call_for_sample('sample_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After your're done with all processing, you will need to close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering a VCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a filtered VCF so that only variants with a `PASS` filter and a VAF over 0.25 will remain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy\n",
    "\n",
    "vcf_reader = vcfpy.Reader.from_path(\"input.vcf\")\n",
    "vcf_writer = vcfpr.Writer.from_path(\"out.vcf\", vcf_reader.header)\n",
    "\n",
    "for entry in vcf_reader:\n",
    "    for alt in entry.ALT:\n",
    "        genotype_bases = entry.call_for_sample('sample_name').gt_bases\n",
    "        if alt in genotype_bases:\n",
    "            if 'PASS' in entry.FILTER and entry.call_for_sample('sample_name')['AF'] > 0.25:\n",
    "                vcf_writer.write_record(entry)\n",
    "        \n",
    "vcf_reader.close()\n",
    "vcf_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a human-readable TSV file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VCFs can often be hard to read since a lot of information is presented in a condensed manner. Let's output some of its information in an easier understandable TSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcfpy\n",
    "import csv\n",
    "\n",
    "vcf_reader = vcfpy.Reader.from_path(\"input.vcf\")\n",
    "with open(\"out.csv\", 'w') as out_fh:\n",
    "    headers = ['CHROM', 'POS', 'REF', 'ALT', 'FILTER', 'DEPTH', 'VAF']\n",
    "    tsv_writer = csv.DictWriter(out_fh, delimiter = '\\t', fieldnames = headers)\n",
    "    tsv_writer.writeheader()\n",
    "    for entry in vcf_reader:\n",
    "        out = {\n",
    "            'CHROM': entry.CHROM,\n",
    "            'POS': entry.POS,\n",
    "            'REF': entry.REF,\n",
    "            'ALT': entry.ALT,\n",
    "            'FILTER': ','.join(entry.FILTER),\n",
    "            'DEPTH': entry.call_for_sample('sample_name')['DP'],\n",
    "            'VAF': ','.join(entry.call_for_sample('sample_name')['AF'])\n",
    "        }\n",
    "        tsv_writer.writerow(out)\n",
    "vcf_reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "samtools pysam \n",
    "biotools? biopython for fasta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
